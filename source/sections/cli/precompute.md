
(precompute)=

# `precompute`

Precomputing data means parsing a dataset in a {ref}`chemical file format<chemical-input>` and computing descriptors for all molecules. This is the first step needed in most pipelines and yields a `precomputed data set` which is the input of (almost) all other programs. The output of `precompute` is a JAR file, including the numerical representation of your input data (potentially altered by any data transformations) and all meta data needed in downstream tasks - such as which descriptors were used, the transformations needed for future predictions, textual labels, the property being modelled etc. 


```{contents} Table of Contents
:backlinks: top
:depth: 3
```

## Usage manual

The full usage manual can be retrieved by running command:

```bash
> ./cpsign-[version]-uber.jar precompute
```

## Data transformations 

The `precompute` program can optionally include data transformations, or for a clearer separation of tasks, these may be included in a separate step using the {ref}`transform <transform>` program. The input of `transform` is, you guessed it, a `precomputed data set` generated by `precompute`. 


(exclusive-datasets)=

## "Exclusive" datasets

CPSign makes it possible to assign portions of data to always be included in model calibration or training of underlying scoring models (i.e. the *calibration set* and *proper training set*). As this is considered non-standard usage these parameters are hidden from the usage of `precompute`, but there is information available from the CLI using `explain exclusive-data`. The basic usage is giving either the `--model-data` (mark data for *proper training set*) or `--calibration-data` (mark data for *calibration set*) and give file-format and sub-arguments using the same syntax as per the `--train-data` parameter. 

For more information on why this can be useful we refer to article [[13]](refs) in references.

**Note:** These parameters are not possible to use when using the TCP, as all the data is used for both training the underlying model and the calibration of the predictions.

## Example usage

Here is a simple example of running `precompute`, where we can walk through the parameters line by line:
1. Invocation of CPSign and specify running the program `precompute`
2. Specify the data set (`--train-data`), the type (`SDF`) and the path to it (`ames.sdf`)
3. Specify which property to use in future modeling steps
4. Specify the possible labels given the property, they can be either "mutagen" or "nonmutagen" - all records with a different value will be filtered out
5. Specify the location in which the precomputed data set should be saved
6. Specify that the time needed to complete each step should be printed on the screen

```bash
> ./cpsign-[version]-uber.jar precompute \
	--train-data SDF ames.sdf \
	--property "Ames test categorisation" \
	--labels mutagen nonmutagen \
	--model-out /output/ames-precomputed.jar \
	--time
```

The output of running this will be something similar to this:

```bash

                           -= CPSign - PRECOMPUTE =-

Validating arguments... [done]
(4 ms)
Reading train file and calculating descriptors...
Successfully parsed 123 molecules. Detected labels: 'mutagen'=64, 
'nonmutagen'=59. Generated 1930 new signatures. Skipped 3 molecule(s) due to 
parsing issues/Heavy Atom Count/ChemDescriptor calculation.
(614 ms)
Saving precomputed data set to file:
/output/ames-precomputed.jar ... [done]
(133 ms)
Program finished in 730 ms
```
